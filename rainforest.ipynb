{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8sALVSeZbDI"
      },
      "source": [
        "### We can construct a mosaic of nearby tiles using this method: https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36738"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as K\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Input, Dense, Activation, BatchNormalization, Flatten\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "import math\n",
        "import re\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yztgcSUwSDwZ"
      },
      "source": [
        "# Preprocess data\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Obtain Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'haze', 1: 'primary', 2: 'agriculture', 3: 'clear', 4: 'water', 5: 'habitation', 6: 'road', 7: 'cultivation', 8: 'slash_burn', 9: 'cloudy', 10: 'partly_cloudy', 11: 'conventional_mine', 12: 'bare_ground', 13: 'artisinal_mine', 14: 'blooming', 15: 'selective_logging', 16: 'blow_down'}\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv('data/train_v2.csv')\n",
        "\n",
        "curr_count = 0\n",
        "unique_labels = {}\n",
        "multihot = {}\n",
        "for line in train_data['tags'].values:\n",
        "    for label in line.split():\n",
        "        if label not in unique_labels:\n",
        "            unique_labels[label] = curr_count\n",
        "            curr_count += 1\n",
        "\n",
        "mapping = {}\n",
        "\n",
        "for k, v in unique_labels.items():\n",
        "    mapping[k] = np.zeros(len(unique_labels))\n",
        "    mapping[k][v] = 1\n",
        "\n",
        "n_labels = len(mapping)\n",
        "label2name = {v: k for k, v in unique_labels.items()}\n",
        "\n",
        "print(label2name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Head of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>haze primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>agriculture clear primary water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>agriculture clear habitation primary road</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>train_5</td>\n",
              "      <td>haze primary water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>train_6</td>\n",
              "      <td>agriculture clear cultivation primary water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>train_7</td>\n",
              "      <td>haze primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>train_8</td>\n",
              "      <td>agriculture clear cultivation primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>train_9</td>\n",
              "      <td>agriculture clear cultivation primary road</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_name                                         tags\n",
              "0    train_0                                 haze primary\n",
              "1    train_1              agriculture clear primary water\n",
              "2    train_2                                clear primary\n",
              "3    train_3                                clear primary\n",
              "4    train_4    agriculture clear habitation primary road\n",
              "5    train_5                           haze primary water\n",
              "6    train_6  agriculture clear cultivation primary water\n",
              "7    train_7                                 haze primary\n",
              "8    train_8        agriculture clear cultivation primary\n",
              "9    train_9   agriculture clear cultivation primary road"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(n = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Auxiliary Function for multi-hotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multihot(label):\n",
        "    z = np.zeros(n_labels)\n",
        "    tokens = label.split(' ')\n",
        "    for k in range(len(tokens)):\n",
        "        z += mapping[tokens[k]]\n",
        "\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "# first pass, construct a list of image strips\n",
        "train_path = 'data/train-jpg/'\n",
        "dataset_length = len(os.listdir(train_path))\n",
        "\n",
        "images_ds = tf.data.Dataset.list_files(f\"{train_path}*\", shuffle = False)\n",
        "steps = math.floor(0.05 * dataset_length)\n",
        "\n",
        "y = np.zeros(shape = (dataset_length, n_labels))\n",
        "for iter, file in enumerate(os.listdir(train_path)[:dataset_length]):\n",
        "    y[iter] = multihot(train_data['tags'][iter])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split into a test and train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(images_ds) = 40479, len(X_train) = 32383, len(X_test) = 8096\n"
          ]
        }
      ],
      "source": [
        "train_length = math.floor(0.8 * dataset_length)\n",
        "X_train, X_test = images_ds.take(train_length), images_ds.skip(train_length)\n",
        "\n",
        "print(f\"{len(images_ds) = }, {len(X_train) = }, {len(X_test) = }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path = <tf.Tensor: shape=(), dtype=string, numpy=b'data\\\\train-jpg\\\\train_0.jpg'>\n",
            "path = <tf.Tensor: shape=(), dtype=string, numpy=b'data\\\\train-jpg\\\\train_1.jpg'>\n",
            "path = <tf.Tensor: shape=(), dtype=string, numpy=b'data\\\\train-jpg\\\\train_10.jpg'>\n"
          ]
        }
      ],
      "source": [
        "for path in X_train.take(3):\n",
        "    print(f'{path = }')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting the first file for testing purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'data\\\\train-jpg\\\\train_0.jpg'\n"
          ]
        }
      ],
      "source": [
        "test_file = None\n",
        "\n",
        "for i in X_train.take(1):\n",
        "    print(i.numpy())\n",
        "    test_file = i.numpy().decode(\"utf-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to grab the label from the filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_label(file_path):\n",
        "    x = file_path.split('\\\\')\n",
        "    file = x[-1]\n",
        "    idx = int(re.findall(r'\\d+', file)[0])\n",
        "\n",
        "    return y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to encode a 2-tuple of tensors from the name of the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_function(filename, resize = [256, 256]):\n",
        "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
        "    Args:\n",
        "        filename: string representing path to image\n",
        "        label: 0/1 one-dimensional array of size N_LABELS\n",
        "    \"\"\"\n",
        "    label = get_label(filename)\n",
        "    # Read an image from a file\n",
        "\n",
        "    img = Image.open(filename).convert(\"RGB\")\n",
        "    img = np.asarray(img) / 255\n",
        "    img = tf.convert_to_tensor(img)\n",
        "    img = tf.image.resize(img, resize)\n",
        "\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dataset(filenames, labels = y, is_training=True):\n",
        "    \"\"\"Load and parse dataset.\n",
        "    Args:\n",
        "        filenames: list of image paths\n",
        "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
        "        is_training: boolean to indicate training mode\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a first dataset of file paths and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "    # Parse and preprocess observations in parallel\n",
        "    dataset = dataset.map(parse_function)\n",
        "        \n",
        "    # Batch the data for multiple steps\n",
        "    dataset = dataset.batch(512)\n",
        "    # # Fetch batches in the background while the model is training.\n",
        "    # dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    \n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = create_dataset(X_train)\n",
        "val_ds = create_dataset(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display a target image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_image(idx, X, y):\n",
        "    img = X[idx]\n",
        "    print(f\"{img = }\")\n",
        "    plt.imshow(img)\n",
        "    plt.title('rinkydinky')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 0\n",
        "batch = None\n",
        "\n",
        "for e in train_ds:\n",
        "    batch = e\n",
        "    break\n",
        "\n",
        "# show_image(0, batch[0], batch[1])\n",
        "batch[0][240]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{batch[0] = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def macro_f1(y, y_hat, thresh=0.5):\n",
        "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
        "    \n",
        "    Args:\n",
        "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "        thresh: probability value above which we predict positive\n",
        "        \n",
        "    Returns:\n",
        "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
        "    \"\"\"\n",
        "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
        "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    macro_f1 = tf.reduce_mean(f1)\n",
        "    return macro_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Construct model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_model = Sequential()\n",
        "\n",
        "ds_model.add(Conv2D(filters = 28,\n",
        "    kernel_size = (3, 3),\n",
        "    input_shape = (256, 256, 3),\n",
        "    activation='relu',\n",
        "    padding = 'Same'))\n",
        "ds_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "ds_model.add(Conv2D(filters = 28,\n",
        "    kernel_size = (3, 3),\n",
        "    activation='relu'))\n",
        "ds_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "ds_model.add(Conv2D(filters = 28,\n",
        "    kernel_size = (3, 3),\n",
        "    activation='relu'))\n",
        "ds_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "ds_model.add(Flatten())\n",
        "\n",
        "ds_model.add(Dense(200, activation = 'relu'))\n",
        "ds_model.add(Dropout(0.2))\n",
        "\n",
        "ds_model.add(Dense(100, activation = 'relu'))\n",
        "ds_model.add(Dropout(0.1))\n",
        "\n",
        "ds_model.add(Dense(n_labels, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt = K.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "ds_model.compile(optimizer=opt,\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics=[macro_f1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndTycMqHSFgl"
      },
      "source": [
        "# Train model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batchsize, epochs = 32, 60\n",
        "\n",
        "ds_history = ds_model.fit(train_ds,\n",
        "    epochs = epochs,\n",
        "    batch_size = batchsize,\n",
        "    validation_data = val_ds,\n",
        "    verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0PFiSDSJr7"
      },
      "source": [
        "# View results\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 0\n",
        "batch1 = None\n",
        "for batch in train_ds:\n",
        "    batch1 = batch\n",
        "    i += 1\n",
        "\n",
        "    if i == 1:\n",
        "        break\n",
        "\n",
        "# NOTE: Batch1 is a TUPLE, not a tensor.\n",
        "# It's comprised of two separate tensors, where the first\n",
        "# element is the set of feature tensors of dimension 512x256x256x3\n",
        "# because each batch is comprised of 512 elements, each being\n",
        "# 256x256x3 images.\n",
        "# The second element in the tuple is the set of multihot encodings\n",
        "\n",
        "print(f\"{batch1 = }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_hat_probs = ds_model.predict(batch1[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_hat_probs[240]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y[240]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPJmOGjzu1qhuay2vw9EljN",
      "collapsed_sections": [],
      "history_visible": true,
      "include_colab_link": true,
      "name": "rainforest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
