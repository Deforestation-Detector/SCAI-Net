{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8sALVSeZbDI"
      },
      "source": [
        "### We can construct a mosaic of nearby tiles using this method: https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36738"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as K\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Input, Dense, Activation, BatchNormalization, Flatten\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yztgcSUwSDwZ"
      },
      "source": [
        "# Preprocess data\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Obtain Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'haze', 1: 'primary', 2: 'agriculture', 3: 'clear', 4: 'water', 5: 'habitation', 6: 'road', 7: 'cultivation', 8: 'slash_burn', 9: 'cloudy', 10: 'partly_cloudy', 11: 'conventional_mine', 12: 'bare_ground', 13: 'artisinal_mine', 14: 'blooming', 15: 'selective_logging', 16: 'blow_down'}\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv('data/train_v2.csv')\n",
        "\n",
        "curr_count = 0\n",
        "unique_labels = {}\n",
        "multihot = {}\n",
        "for line in train_data['tags'].values:\n",
        "    for label in line.split():\n",
        "        if label not in unique_labels:\n",
        "            unique_labels[label] = curr_count\n",
        "            curr_count += 1\n",
        "\n",
        "mapping = {}\n",
        "\n",
        "for k, v in unique_labels.items():\n",
        "    mapping[k] = np.zeros(len(unique_labels))\n",
        "    mapping[k][v] = 1\n",
        "\n",
        "n_labels = len(mapping)\n",
        "label2name = {v: k for k, v in unique_labels.items()}\n",
        "\n",
        "print(label2name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Head of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>haze primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>agriculture clear primary water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>agriculture clear habitation primary road</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>train_5</td>\n",
              "      <td>haze primary water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>train_6</td>\n",
              "      <td>agriculture clear cultivation primary water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>train_7</td>\n",
              "      <td>haze primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>train_8</td>\n",
              "      <td>agriculture clear cultivation primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>train_9</td>\n",
              "      <td>agriculture clear cultivation primary road</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_name                                         tags\n",
              "0    train_0                                 haze primary\n",
              "1    train_1              agriculture clear primary water\n",
              "2    train_2                                clear primary\n",
              "3    train_3                                clear primary\n",
              "4    train_4    agriculture clear habitation primary road\n",
              "5    train_5                           haze primary water\n",
              "6    train_6  agriculture clear cultivation primary water\n",
              "7    train_7                                 haze primary\n",
              "8    train_8        agriculture clear cultivation primary\n",
              "9    train_9   agriculture clear cultivation primary road"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(n = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define multihot mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Auxiliary Function for multi-hotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multihot(label):\n",
        "    z = np.zeros(17)\n",
        "    tokens = label.split(' ')\n",
        "    for k in range(len(tokens)):\n",
        "        z += mapping[tokens[k]]\n",
        "\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00 % complete\n",
            "5.00 % complete\n",
            "10.00 % complete\n",
            "15.00 % complete\n",
            "20.00 % complete\n",
            "25.00 % complete\n",
            "30.00 % complete\n",
            "35.00 % complete\n",
            "40.00 % complete\n",
            "45.00 % complete\n",
            "50.00 % complete\n",
            "55.00 % complete\n",
            "60.00 % complete\n",
            "65.00 % complete\n",
            "70.00 % complete\n",
            "75.00 % complete\n",
            "80.00 % complete\n",
            "85.00 % complete\n",
            "90.00 % complete\n",
            "95.00 % complete\n"
          ]
        }
      ],
      "source": [
        "# first pass, construct a list of image strips\n",
        "\n",
        "train_path = 'data/train-jpg/'\n",
        "\n",
        "num_images = len(os.listdir(train_path))\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "num_jpgs = 1000\n",
        "for iter, file in enumerate(os.listdir(train_path)[:num_jpgs]):\n",
        "    X.append(file)\n",
        "    y.append(train_data['tags'][iter])\n",
        "\n",
        "    if iter % (0.05 * num_jpgs) == 0:\n",
        "        print(f\"{(100 * iter / num_jpgs):.2f} % complete\")\n",
        "\n",
        "# X_np = np.array(X) / 255\n",
        "\n",
        "y_np = np.zeros(shape = (num_jpgs, n_labels))\n",
        "\n",
        "\n",
        "for i, label in enumerate(y):\n",
        "    y_np[i] = multihot(label)\n",
        "\n",
        "y = y_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_split = 0.2\n",
        "\n",
        "indices = np.random.permutation(len(X))\n",
        "train_length = math.floor(indices.shape[0] * (1 - validation_split))\n",
        "train_indices, test_indices = indices[0:train_length], indices[train_length:]\n",
        "\n",
        "X_train, X_test = [], []\n",
        "y_train, y_test = [], []\n",
        "\n",
        "for i in train_indices:\n",
        "    X_train.append(X[i])\n",
        "    y_train.append(y[i])\n",
        "\n",
        "for j in test_indices:\n",
        "    X_test.append(X[i])\n",
        "    y_test.append(y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_function(filename, label):\n",
        "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
        "    Args:\n",
        "        filename: string representing path to image\n",
        "        label: 0/1 one-dimensional array of size N_LABELS\n",
        "    \"\"\"\n",
        "    # Read an image from a file\n",
        "    image_string = tf.io.read_file(filename)\n",
        "\n",
        "    # Decode it into a dense vector\n",
        "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "\n",
        "    # Resize it to fixed shape\n",
        "    image_resized = tf.image.resize(image_decoded, [256, 256])\n",
        "\n",
        "    print(f\"{image_resized[0] = }\")\n",
        "\n",
        "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
        "    image_normalized = image_resized / 255.0\n",
        "    return image_normalized, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dataset(filenames, labels, is_training=True):\n",
        "    \"\"\"Load and parse dataset.\n",
        "    Args:\n",
        "        filenames: list of image paths\n",
        "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
        "        is_training: boolean to indicate training mode\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create a first dataset of file paths and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "    # Parse and preprocess observations in parallel\n",
        "    dataset = dataset.map(parse_function)\n",
        "    \n",
        "    # if is_training == True:\n",
        "    #     # This is a small dataset, only load it once, and keep it in memory.\n",
        "    #     dataset = dataset.cache()\n",
        "    #     # Shuffle the data each buffer size\n",
        "    #     dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "        \n",
        "    # Batch the data for multiple steps\n",
        "    dataset = dataset.batch(256)\n",
        "    # # Fetch batches in the background while the model is training.\n",
        "    # dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    \n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_resized[0] = <tf.Tensor 'strided_slice:0' shape=(256, 3) dtype=float32>\n",
            "image_resized[0] = <tf.Tensor 'strided_slice:0' shape=(256, 3) dtype=float32>\n"
          ]
        }
      ],
      "source": [
        "train_ds = create_dataset(X_train, y_train)\n",
        "val_ds = create_dataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 256, 256, 3), (None, 17)), types: (tf.float32, tf.float64)>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display a target image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'BatchDataset' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18296/200536353.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18296/200536353.py\u001b[0m in \u001b[0;36mshow_image\u001b[1;34m(idx, X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "def show_image(idx, X, y):\n",
        "    img = X[idx]\n",
        "    plt.imshow(img)\n",
        "    plt.title(y[idx])\n",
        "    plt.show()\n",
        "\n",
        "show_image(1, train_ds, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split into a test and train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type(y) = <class 'list'>\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "only integer scalar arrays can be converted to a scalar index",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18296/978095367.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ],
      "source": [
        "validation_split = 0.2\n",
        "\n",
        "indices = np.random.permutation(X.shape[0])\n",
        "train_length = math.floor(indices.shape[0] * (1 - validation_split))\n",
        "train_indices, test_indices = indices[0:train_length], indices[train_length:]\n",
        "\n",
        "print(f'{type(y) = }')\n",
        "\n",
        "(X_train, X_test) = (X[train_indices], X[test_indices]) \n",
        "(y_train, y_test) = (y[train_indices], y[test_indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Construct model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_model = Sequential()\n",
        "\n",
        "ds_model.add(Conv2D(filters = 28,\n",
        "    kernel_size = (3, 3),\n",
        "    input_shape = (256, 256, 3),\n",
        "    activation='relu',\n",
        "    padding = 'Same'))\n",
        "ds_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "ds_model.add(Conv2D(filters = 28,\n",
        "    kernel_size = (3, 3),\n",
        "    input_shape = (256, 256, 3),\n",
        "    activation='relu'))\n",
        "ds_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "ds_model.add(Conv2D(filters = 28,\n",
        "    kernel_size = (3, 3),\n",
        "    input_shape = (256, 256, 3),\n",
        "    activation='relu'))\n",
        "ds_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "ds_model.add(Flatten())\n",
        "\n",
        "ds_model.add(Dense(200, activation = 'relu'))\n",
        "ds_model.add(Dropout(0.2))\n",
        "\n",
        "ds_model.add(Dense(100, activation = 'softmax'))\n",
        "\n",
        "opt = K.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "ds_model.compile(optimizer=opt,\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "batchsize, epochs = 64, 3\n",
        "\n",
        "ds_history = ds_model.fit(X_train, y_train,\n",
        "    epochs = epochs,\n",
        "    batch_size = batchsize,\n",
        "    validation_split = 0.2,\n",
        "    verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndTycMqHSFgl"
      },
      "source": [
        "# Train model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0PFiSDSJr7"
      },
      "source": [
        "# View results\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPJmOGjzu1qhuay2vw9EljN",
      "collapsed_sections": [],
      "history_visible": true,
      "include_colab_link": true,
      "name": "rainforest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
