{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8sALVSeZbDI"
      },
      "source": [
        "### We can construct a mosaic of nearby tiles using this method: https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36738"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Construct image tile mosaic\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# first pass, construct a list of image strips\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "train_path = 'data/train-jpg/'\n",
        "\n",
        "image_strip_list = []\n",
        "for file in os.listdir(train_path):\n",
        "    # load image as numpy array\n",
        "    image = matplotlib.image.imread('data/train-jpg/train_1.jpg')\n",
        "\n",
        "    # drop alpha channel\n",
        "    image = image[:, :, :3]\n",
        "\n",
        "    # 1) Get vectors of all edges of images. So 4 vectors of size 3*256 for each image.\n",
        "    left = image[:, 0, :]\n",
        "    right = image[:, 255, :]\n",
        "    top = image[0, :, :]\n",
        "    bottom = image[255, :, :]\n",
        "\n",
        "    # append to list containing 4-tuples of image strips: (left, right, top, bottom)\n",
        "    image_strip_list.append( (left, right, top, bottom) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# second pass, find neighboring images based on their strips\n",
        "\n",
        "# for image in image_strip_list:\n",
        "    # 2) For each image find difference between top vector and bottom vector of all other images. Take the minimum. It will be the TOP neighbour. Do the same for BOTTOM, LEFT and RIGHT.\n",
        "\n",
        "    # 3) Using the same algorithm get neighbours for all TIFF images.\n",
        "\n",
        "    # 4) Remove neighbours which is different for JPG and TIFF images.\n",
        "\n",
        "    # 5) Use diagonals to additional improvements. For example check that diagonal element have same neighbours as central one without conflicts and so onâ€¦\n",
        "\n",
        "    # 6) Use CNN averaged predictions for 4 or 8 neighbours as features for central element"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yztgcSUwSDwZ"
      },
      "source": [
        "# Preprocess data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['haze primary' 'agriculture clear primary water' 'clear primary' ...\n",
            " 'agriculture clear primary' 'agriculture clear primary road'\n",
            " 'agriculture cultivation partly_cloudy primary']\n",
            "haze\n",
            "primary\n",
            "agriculture\n",
            "clear\n",
            "water\n",
            "habitation\n",
            "road\n",
            "cultivation\n",
            "slash_burn\n",
            "cloudy\n",
            "partly_cloudy\n",
            "conventional_mine\n",
            "bare_ground\n",
            "artisinal_mine\n",
            "blooming\n",
            "selective_logging\n",
            "blow_down\n",
            "17\n"
          ]
        }
      ],
      "source": [
        "# extract labels from training data\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('data/train_v2.csv/train_v2.csv')\n",
        "print(train_data['tags'].values)\n",
        "\n",
        "unique_labels = []\n",
        "for line in train_data['tags'].values:\n",
        "    for label in line.split():\n",
        "        if label not in unique_labels:\n",
        "            unique_labels.append(label)\n",
        "            print(label)\n",
        "\n",
        "print(len(unique_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xaJCZcWSH19"
      },
      "source": [
        "# Construct model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndTycMqHSFgl"
      },
      "source": [
        "# Train model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0PFiSDSJr7"
      },
      "source": [
        "# View results\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPJmOGjzu1qhuay2vw9EljN",
      "collapsed_sections": [],
      "history_visible": true,
      "include_colab_link": true,
      "name": "rainforest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
