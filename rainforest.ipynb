{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8sALVSeZbDI"
      },
      "source": [
        "### We can construct a mosaic of nearby tiles using this method: https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36738"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Construct image tile mosaic\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00 % complete\n",
            "1.24 % complete\n",
            "2.47 % complete\n",
            "3.71 % complete\n",
            "4.94 % complete\n",
            "6.18 % complete\n",
            "7.41 % complete\n",
            "8.65 % complete\n",
            "9.88 % complete\n",
            "11.12 % complete\n",
            "12.35 % complete\n",
            "13.59 % complete\n",
            "14.82 % complete\n",
            "16.06 % complete\n",
            "17.29 % complete\n",
            "18.53 % complete\n",
            "19.76 % complete\n",
            "21.00 % complete\n",
            "22.23 % complete\n",
            "23.47 % complete\n",
            "24.70 % complete\n",
            "25.94 % complete\n",
            "27.17 % complete\n",
            "28.41 % complete\n",
            "29.65 % complete\n",
            "30.88 % complete\n",
            "32.12 % complete\n",
            "33.35 % complete\n",
            "34.59 % complete\n",
            "35.82 % complete\n",
            "37.06 % complete\n",
            "38.29 % complete\n",
            "39.53 % complete\n",
            "40.76 % complete\n",
            "42.00 % complete\n",
            "43.23 % complete\n",
            "44.47 % complete\n",
            "45.70 % complete\n",
            "46.94 % complete\n",
            "48.17 % complete\n",
            "49.41 % complete\n",
            "50.64 % complete\n",
            "51.88 % complete\n",
            "53.11 % complete\n",
            "54.35 % complete\n",
            "55.58 % complete\n",
            "56.82 % complete\n",
            "58.05 % complete\n",
            "59.29 % complete\n",
            "60.53 % complete\n",
            "61.76 % complete\n",
            "63.00 % complete\n",
            "64.23 % complete\n",
            "65.47 % complete\n",
            "66.70 % complete\n",
            "67.94 % complete\n",
            "69.17 % complete\n",
            "70.41 % complete\n",
            "71.64 % complete\n",
            "72.88 % complete\n",
            "74.11 % complete\n",
            "75.35 % complete\n",
            "76.58 % complete\n",
            "77.82 % complete\n",
            "79.05 % complete\n",
            "80.29 % complete\n",
            "81.52 % complete\n",
            "82.76 % complete\n",
            "83.99 % complete\n",
            "85.23 % complete\n",
            "86.46 % complete\n",
            "87.70 % complete\n",
            "88.94 % complete\n",
            "90.17 % complete\n",
            "91.41 % complete\n",
            "92.64 % complete\n",
            "93.88 % complete\n",
            "95.11 % complete\n",
            "96.35 % complete\n",
            "97.58 % complete\n",
            "98.82 % complete\n"
          ]
        }
      ],
      "source": [
        "# first pass, construct a list of image strips\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "train_path = 'data/train-jpg/'\n",
        "\n",
        "num_images = len(os.listdir(train_path))\n",
        "\n",
        "image_strip_list = []\n",
        "\n",
        "num_jpgs = num_images\n",
        "for iter, file in enumerate(os.listdir(train_path)[:num_jpgs]):\n",
        "    # print(f\"iter = {iter}\")\n",
        "    # load image as numpy array\n",
        "    image = matplotlib.image.imread(train_path + file)\n",
        "\n",
        "    # drop alpha channel\n",
        "    image = image[:, :, :3]\n",
        "\n",
        "    # 1) Get vectors of all edges of images. So 4 vectors of size 3*256 for each image.\n",
        "    left = image[:, 0, :]\n",
        "    right = image[:, 255, :]\n",
        "    top = image[0, :, :]\n",
        "    bottom = image[255, :, :]\n",
        "\n",
        "    # append to list containing 4-tuples of image strips: (left, right, top, bottom)\n",
        "    image_strip_list.append( (left, right, top, bottom) )\n",
        "\n",
        "    if iter % 500 == 0:\n",
        "        print(f\"{(100 * iter / num_jpgs):.2f} % complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5 % complete, image_index = 125\n",
            "5.0 % complete, image_index = 250\n",
            "7.5 % complete, image_index = 375\n",
            "10.0 % complete, image_index = 500\n",
            "12.5 % complete, image_index = 625\n",
            "15.0 % complete, image_index = 750\n",
            "17.5 % complete, image_index = 875\n",
            "20.0 % complete, image_index = 1000\n",
            "22.5 % complete, image_index = 1125\n",
            "25.0 % complete, image_index = 1250\n",
            "27.5 % complete, image_index = 1375\n",
            "30.0 % complete, image_index = 1500\n",
            "32.5 % complete, image_index = 1625\n",
            "35.0 % complete, image_index = 1750\n",
            "37.5 % complete, image_index = 1875\n",
            "40.0 % complete, image_index = 2000\n",
            "42.5 % complete, image_index = 2125\n",
            "45.0 % complete, image_index = 2250\n",
            "47.5 % complete, image_index = 2375\n",
            "50.0 % complete, image_index = 2500\n",
            "52.5 % complete, image_index = 2625\n",
            "55.0 % complete, image_index = 2750\n",
            "57.5 % complete, image_index = 2875\n",
            "60.0 % complete, image_index = 3000\n",
            "62.5 % complete, image_index = 3125\n",
            "65.0 % complete, image_index = 3250\n",
            "67.5 % complete, image_index = 3375\n",
            "70.0 % complete, image_index = 3500\n",
            "72.5 % complete, image_index = 3625\n",
            "75.0 % complete, image_index = 3750\n",
            "77.5 % complete, image_index = 3875\n",
            "80.0 % complete, image_index = 4000\n",
            "82.5 % complete, image_index = 4125\n",
            "85.0 % complete, image_index = 4250\n",
            "87.5 % complete, image_index = 4375\n",
            "90.0 % complete, image_index = 4500\n",
            "92.5 % complete, image_index = 4625\n",
            "95.0 % complete, image_index = 4750\n",
            "97.5 % complete, image_index = 4875\n"
          ]
        }
      ],
      "source": [
        "# second pass, find neighboring images based on their strips\n",
        "\n",
        "# In this algorithm, we assume that images have not been rotated\n",
        "\n",
        "# 2) For each image find difference between top vector and bottom vector of all other images. Take the minimum. It will be the TOP neighbour. Do the same for BOTTOM, LEFT and RIGHT.\n",
        "\n",
        "# my idea: construct a dictionary where: \n",
        "#   * key is an integer representing the image name\n",
        "#   * value is a 4-list of 2-lists\n",
        "#       * 4-list: [ [left, diff.], [right, diff.], [top, diff.], [bottom, diff.] ]\n",
        "# The 4-list represents the current best neighboring images and their\n",
        "# difference (after subtracting two image strips)\n",
        "\n",
        "INIT_DIFF = 999999999\n",
        "\n",
        "image_mosaic_dict = {i:[[None, INIT_DIFF], [None, INIT_DIFF], [None, INIT_DIFF], [None, INIT_DIFF]] for i in range(num_images)}\n",
        "\n",
        "for image_index, image in enumerate(image_strip_list):\n",
        "\n",
        "    # iterate over image strip sides. Note:\n",
        "    # strip_indices are defined as follows:\n",
        "    # 0: left\n",
        "    # 1: right\n",
        "    # 2: top\n",
        "    # 3: bottom\n",
        "\n",
        "    for strip_index, strip in enumerate(image):\n",
        "\n",
        "        # check to see if strip already has a neighbor\n",
        "        neighbor = image_mosaic_dict[image_index][strip_index][0]\n",
        "        difference = image_mosaic_dict[image_index][strip_index][1]\n",
        "\n",
        "        for possible_index, (possible_left, possible_right, possible_top, possible_bottom) in enumerate(image_strip_list):\n",
        "\n",
        "            # image cannot match with itself\n",
        "            if image_index == possible_index:\n",
        "                continue\n",
        "\n",
        "            # strip is left, search for rights\n",
        "            if strip_index == 0:\n",
        "            \n",
        "                # if difference is greater, take the new strip\n",
        "                new_difference = np.abs(np.sum(strip - possible_right))\n",
        "                if new_difference < difference:\n",
        "                    # update current strip info\n",
        "                    image_mosaic_dict[image_index][strip_index][0] = possible_index\n",
        "                    image_mosaic_dict[image_index][strip_index][1] = new_difference\n",
        "\n",
        "                    # update new neighboring strip info\n",
        "                    image_mosaic_dict[possible_index][1][0] = image_index\n",
        "                    image_mosaic_dict[possible_index][1][1] = new_difference\n",
        "\n",
        "            # strip is right, search for lefts\n",
        "            elif strip_index == 1:\n",
        "\n",
        "                    # if difference is greater, take the new strip\n",
        "                    new_difference = np.abs(np.sum(strip - possible_left))\n",
        "                    if new_difference < difference:\n",
        "                        # update current strip info\n",
        "                        image_mosaic_dict[image_index][strip_index][0] = possible_index\n",
        "                        image_mosaic_dict[image_index][strip_index][1] = new_difference\n",
        "\n",
        "                        # update new neighboring strip info\n",
        "                        image_mosaic_dict[possible_index][0][0] = image_index\n",
        "                        image_mosaic_dict[possible_index][0][1] = new_difference\n",
        "\n",
        "            # strip is top, search for bottoms\n",
        "            elif strip_index == 2:\n",
        "\n",
        "                # if difference is greater, take the new strip\n",
        "                new_difference = np.abs(np.sum(strip - possible_bottom))\n",
        "                if new_difference < difference:\n",
        "                    # update current strip info\n",
        "                    image_mosaic_dict[image_index][strip_index][0] = possible_index\n",
        "                    image_mosaic_dict[image_index][strip_index][1] = new_difference\n",
        "\n",
        "                    # update new neighboring strip info\n",
        "                    image_mosaic_dict[possible_index][3][0] = image_index\n",
        "                    image_mosaic_dict[possible_index][3][1] = new_difference\n",
        "\n",
        "            # strip is bottom, search for tops\n",
        "            elif strip_index == 3:\n",
        "                \n",
        "                # if difference is greater, take the new strip\n",
        "                new_difference = np.abs(np.sum(strip - possible_top))\n",
        "                if new_difference < difference:\n",
        "                    # update current strip info\n",
        "                    image_mosaic_dict[image_index][strip_index][0] = possible_index\n",
        "                    image_mosaic_dict[image_index][strip_index][1] = new_difference\n",
        "\n",
        "                    # update new neighboring strip info\n",
        "                    image_mosaic_dict[possible_index][2][0] = image_index\n",
        "                    image_mosaic_dict[possible_index][2][1] = new_difference\n",
        "    \n",
        "    if image_index % 125 == 0 and image_index != 0:\n",
        "            print(f\"{(100 * image_index / num_jpgs)} % complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.0 % complete\n",
            "10.0 % complete\n",
            "15.0 % complete\n",
            "20.0 % complete\n",
            "25.0 % complete\n",
            "30.0 % complete\n",
            "35.0 % complete\n",
            "40.0 % complete\n",
            "45.0 % complete\n",
            "50.0 % complete\n",
            "55.0 % complete\n",
            "60.0 % complete\n",
            "65.0 % complete\n",
            "70.0 % complete\n",
            "75.0 % complete\n",
            "80.0 % complete\n",
            "85.0 % complete\n",
            "90.0 % complete\n",
            "95.0 % complete\n"
          ]
        }
      ],
      "source": [
        "# second pass, find neighboring images based on their strips\n",
        "\n",
        "# In this algorithm, we assume that images have not been rotated\n",
        "\n",
        "# 2) For each image find difference between top vector and bottom vector of all other images. Take the minimum. It will be the TOP neighbour. Do the same for BOTTOM, LEFT and RIGHT.\n",
        "\n",
        "# my idea: construct a dictionary where: \n",
        "#   * key is an integer representing the image name\n",
        "#   * value is a 4-list of 2-lists\n",
        "#       * 4-list: [ [left, diff.], [right, diff.], [top, diff.], [bottom, diff.] ]\n",
        "# The 4-list represents the current best neighboring images and their\n",
        "# difference (after subtracting two image strips)\n",
        "\n",
        "INIT_DIFF = float('inf')\n",
        "\n",
        "image_mosaic_dict = {i:[[None, INIT_DIFF], [None, INIT_DIFF], [None, INIT_DIFF], [None, INIT_DIFF]] for i in range(num_images)}\n",
        "\n",
        "for image_index, image in enumerate(image_strip_list):\n",
        "\n",
        "    # iterate over image strip sides. Note:\n",
        "    # strip_indices are defined as follows:\n",
        "    # 0: left\n",
        "    # 1: right\n",
        "    # 2: top\n",
        "    # 3: bottom\n",
        "    # check to see if strip already has a neighbor\n",
        "    neighbor = image_mosaic_dict[image_index][strip_index][0]\n",
        "    difference = image_mosaic_dict[image_index][strip_index][1]\n",
        "\n",
        "    (strip_left, strip_right, strip_top, strip_bottom) = image_strip_list[image_index]\n",
        "\n",
        "    for possible_index, (possible_left, possible_right, possible_top, possible_bottom) in enumerate(image_strip_list):\n",
        "\n",
        "        # image cannot match with itself\n",
        "        if image_index == possible_index:\n",
        "            continue\n",
        "\n",
        "        # Comparing left side of current image with right side of possible neighbor\n",
        "        new_difference = np.abs(np.sum(strip_left - possible_right))\n",
        "        if new_difference < difference:\n",
        "            # update current strip info\n",
        "            image_mosaic_dict[image_index][0][0] = possible_index\n",
        "            image_mosaic_dict[image_index][0][1] = new_difference\n",
        "\n",
        "        # Comparing right side of current image with left side of possible neighbor\n",
        "        new_difference = np.abs(np.sum(strip_right - possible_left))\n",
        "        if new_difference < difference:\n",
        "            # update current strip info\n",
        "            image_mosaic_dict[image_index][1][0] = possible_index\n",
        "            image_mosaic_dict[image_index][1][1] = new_difference\n",
        "        \n",
        "        # Comparing top side of current image with bottom side of possible neighbor\n",
        "        new_difference = np.abs(np.sum(strip_top - possible_bottom))\n",
        "        if new_difference < difference:\n",
        "            # update current strip info\n",
        "            image_mosaic_dict[image_index][2][0] = possible_index\n",
        "            image_mosaic_dict[image_index][2][1] = new_difference\n",
        "\n",
        "        # Comparing bottom side of current image with top side of possible neighbor\n",
        "        new_difference = np.abs(np.sum(strip_bottom - possible_top))\n",
        "        if new_difference < difference:\n",
        "            # update current strip info\n",
        "            image_mosaic_dict[image_index][3][0] = possible_index\n",
        "            image_mosaic_dict[image_index][3][1] = new_difference\n",
        "    \n",
        "    if image_index % 250 == 0 and image_index != 0:\n",
        "            print(f\"{(100 * image_index / num_jpgs)} % complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "found top: curr = 2016, neighbor_index = 4914 w/ diff = 40555\n",
            "found top: curr = 3735, neighbor_index = 4664 w/ diff = 32955\n",
            "found left: curr = 4160, neighbor = 4995 w/ diff = 27306\n",
            "found bottom: curr = 4292, neighbor = 4876 w/ diff = 11828\n",
            "curr_min = 27306\n",
            "found left: curr = 4750, neighbor = 4896 w/ diff = 11787\n",
            "found top: curr = 4839, neighbor_index = 4876 w/ diff = 11549\n",
            "curr = 4839, curr_neighbor = 4876 and curr_min = 11549\n"
          ]
        }
      ],
      "source": [
        "# PEOPLE ON THE KAGGLE FORUMS SAY THAT, (in general), THE .tiff IMAGES WERE NOT \n",
        "# USEFUL. That might be the same case here.\n",
        "\n",
        "# 3) Using the same algorithm get neighbours for all TIFF images.\n",
        "\n",
        "# 4) Remove neighbours which is different for JPG and TIFF images.\n",
        "\n",
        "# 5) Use diagonals to additional improvements. For example check that diagonal element have same neighbours as central one without conflicts and so onâ€¦\n",
        "\n",
        "# 6) Use CNN averaged predictions for 4 or 8 neighbours as features for central element\n",
        "\n",
        "curr_min = float('inf')\n",
        "curr = curr_neighbor = 0\n",
        "for index in image_mosaic_dict:\n",
        "    neighbor_index = image_mosaic_dict[index][0][0]\n",
        "    if image_mosaic_dict[neighbor_index][1][0] == index and image_mosaic_dict[index][0][1] < curr_min:\n",
        "        print(f\"found left: curr = {index}, neighbor = {neighbor_index} w/ diff = {image_mosaic_dict[index][0][1]}\")\n",
        "        curr_min = image_mosaic_dict[index][0][1]\n",
        "        curr, curr_neighbor = index, neighbor_index\n",
        "    \n",
        "    neighbor_index = image_mosaic_dict[index][1][0]\n",
        "    if image_mosaic_dict[neighbor_index][0][0] == index and image_mosaic_dict[index][1][1] < curr_min:\n",
        "        print(f\"found right: curr = {index}, neighbor = {neighbor_index} w/ diff = {image_mosaic_dict[index][1][1]}\")\n",
        "        curr_min = image_mosaic_dict[index][1][1]\n",
        "        curr, curr_neighbor = index, neighbor_index\n",
        "\n",
        "    neighbor_index = image_mosaic_dict[index][2][0]\n",
        "    if image_mosaic_dict[neighbor_index][3][0] == index and image_mosaic_dict[index][2][1] < curr_min:\n",
        "        print(f\"found top: curr = {index}, neighbor_index = {neighbor_index} w/ diff = {image_mosaic_dict[index][2][1]}\")\n",
        "        curr_min = image_mosaic_dict[index][2][1]\n",
        "        curr, curr_neighbor = index, neighbor_index\n",
        "    \n",
        "    neighbor_index = image_mosaic_dict[index][3][0]\n",
        "    if image_mosaic_dict[neighbor_index][2][0] == index and image_mosaic_dict[index][3][1] < curr_min:\n",
        "        print(f\"found bottom: curr = {index}, neighbor = {neighbor_index} w/ diff = {image_mosaic_dict[index][3][1]}\")\n",
        "        print(f'curr_min = {curr_min}')\n",
        "        curr_min = image_mosaic_dict[index][3][1]\n",
        "        curr, curr_neighbor = index, neighbor_index\n",
        "    \n",
        "    if index == 4999:\n",
        "        break\n",
        "\n",
        "print(f\"curr = {curr}, curr_neighbor = {curr_neighbor} and curr_min = {curr_min}\")\n",
        "# print(image_mosaic_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yztgcSUwSDwZ"
      },
      "source": [
        "# Preprocess data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['haze primary' 'agriculture clear primary water' 'clear primary' ...\n",
            " 'agriculture clear primary' 'agriculture clear primary road'\n",
            " 'agriculture cultivation partly_cloudy primary']\n",
            "haze\n",
            "primary\n",
            "agriculture\n",
            "clear\n",
            "water\n",
            "habitation\n",
            "road\n",
            "cultivation\n",
            "slash_burn\n",
            "cloudy\n",
            "partly_cloudy\n",
            "conventional_mine\n",
            "bare_ground\n",
            "artisinal_mine\n",
            "blooming\n",
            "selective_logging\n",
            "blow_down\n",
            "17\n"
          ]
        }
      ],
      "source": [
        "# extract labels from training data\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('data/train_v2.csv/train_v2.csv')\n",
        "print(train_data['tags'].values)\n",
        "\n",
        "unique_labels = []\n",
        "for line in train_data['tags'].values:\n",
        "    for label in line.split():\n",
        "        if label not in unique_labels:\n",
        "            unique_labels.append(label)\n",
        "            print(label)\n",
        "\n",
        "print(len(unique_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xaJCZcWSH19"
      },
      "source": [
        "# Construct model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndTycMqHSFgl"
      },
      "source": [
        "# Train model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0PFiSDSJr7"
      },
      "source": [
        "# View results\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPJmOGjzu1qhuay2vw9EljN",
      "collapsed_sections": [],
      "history_visible": true,
      "include_colab_link": true,
      "name": "rainforest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
